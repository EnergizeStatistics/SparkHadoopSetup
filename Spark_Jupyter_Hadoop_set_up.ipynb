{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**_Most of the shell commands are to be executed in Linux terminal. The configuration file edits and R commands are marked_**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check OS default Python\n",
    "which python\n",
    "# If line above does not return anything, then no default Python interpreter is designated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check OS Python version.\n",
    "# Ubuntu comes with both Python 2 and Python 3. We don't need to install either of them but we do need to check which one is the default. \n",
    "python -V\n",
    "# Expect \"Python3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify whether there is default Python interpreter\n",
    "dpkg -S /usr/bin/python\n",
    "# Expect this to return \"not found\". If not, adjust the next step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make Python3 the default\n",
    "sudo ln -sf /usr/bin/python3 /usr/bin/python\n",
    "# Verify success\n",
    "python -V\n",
    "# Expect a Python 3 version number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install Java\n",
    "sudo apt-get install default-jdk\n",
    "\n",
    "# Install numpy\n",
    "apt-get install python3-numpy\n",
    "\n",
    "# Install pip\n",
    "sudo apt-get install python3-pip\n",
    "\n",
    "# Install Jupyter Notebook\n",
    "sudo -H pip3 install jupyter\n",
    "\n",
    "# Install R\n",
    "sudo apt-get install r-base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start R\n",
    "sudo R"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**In R console:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install SparkR dependencies\n",
    "install.packages(\"rJava\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Go back to terminal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now download Spark installation package. The download link changes as new versions of Spark are released.\n",
    "Visit https://spark.apache.org/downloads.html beforehand to find the latest download link. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download Spark installation package.\n",
    "wget https://www.apache.org/dyn/closer.lua/spark/spark-2.2.0/spark-2.2.0-bin-hadoop2.7.tgz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unzip\n",
    "tar -xzf spark-2.2.0-bin-hadoop2.7.tgz\n",
    "\n",
    "# Move the folder to /opt/, as Spark is not part of the Ubuntu distribution or managed by the Ubuntu distribution package manager\n",
    "mv spark-2.2.0-bin-hadoop2.7 /opt/spark-2.2.0\n",
    "\n",
    "# Create a symbolic link for spark\n",
    "ln -s /opt/spark-2.2.0 /opt/spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tell bash where to find Spark\n",
    "nano ~/.bashrc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**In editor:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add these two lines:\n",
    "export SPARK_HOME=/opt/spark\n",
    "export PATH=$SPARK_HOME/bin:$PATH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save and go back to terminal. Start R."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**In R console:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test SparkR\n",
    "library(SparkR, lib.loc = \"/opt/spark/R/lib/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Back to terminal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies for Jupyter to use R\n",
    "apt-get install libssl-dev\n",
    "apt-get install libcurl4-openssl-dev"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**In R console:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install Jupyter R kernel\n",
    "# author's instructions: https://irkernel.github.io/installation/\n",
    "install.packages(c('repr', 'IRdisplay', 'evaluate', 'crayon', 'pbdZMQ', 'devtools', 'uuid', 'digest'))\n",
    "devtools::install_github('IRkernel/IRkernel')\n",
    "IRkernel::installspec(user = TRUE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Back to terminal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add PySpark driver environment variables to bash\n",
    "nano ~/.bashrc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**In editor:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "export PYSPARK_DRIVER_PYTHON=jupyter\n",
    "export PYSPARK_DRIVER_PYTHON_OPTS='notebook'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save, restart terminal. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# launch PySpark\n",
    "pyspark\n",
    "# Rather than command line PySpark, expect a Jupyter Notebook to start in web browser."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download Hadoop installation package. Link for download address: http://hadoop.apache.org/releases.html, under \"binary\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download Hadoop installation package\n",
    "wget http://www.apache.org/dyn/closer.cgi/hadoop/common/hadoop-2.7.4/hadoop-2.7.4.tar.gz\n",
    "\n",
    "# Unzip\n",
    "tar -xzvf hadoop-2.7.4.tar.gz\n",
    "\n",
    "# Move to /opt/\n",
    "sudo mv hadoop-2.7.4 /opt/hadoop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure Hadoop's Java Home\n",
    "nano /opt/hadoop/etc/hadoop/hadoop-env.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**In editor:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comment out `export JAVA_HOME=${JAVA_HOME}`\n",
    "export JAVA_HOME=$(readlink -f /usr/bin/java | sed \"s:bin/java::\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save, back to terminal. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Hadoop\n",
    "/opt/hadoop/bin/hadoop"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
